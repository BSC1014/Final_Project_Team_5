{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "   \"rating_good_or_bad\",\"accept_rate_below_avg\",\"accept_rate_above_avg\",\"response_rate_below_avg\",\"response_rate_above_avg\",\"below_avg_num_of_reviews\",\n",
    "   \"above_avg_num_of_reviews\",\"below_avg_num_of_accom\",\"above_avg_num_of_accom\",\"below_avg_num_of_bedrooms\",\"above_avg_num_of_bedrooms\",\"below_avg_num_of_beds\",\n",
    "   \"above_avg_num_of_beds\",\"below_avg_num_of_baths\",\"above_avg_num_of_baths\",\"not_a_superhost\",\"a_superhost\",\"host_does_not_have_profile_pic\",\n",
    "   \"host_does_have_profile_pic\",\"host_does_not_have_identity_ver\",\"host_does_have_identity_ver\",\"not_instantly_bookable\",\"instantly_bookable\",\n",
    "   \"does_not_require_guest_prof_pic\",\"requires_guest_profile_pic\",\"does_not_require_guest_phone_verification\",\"requires_guest_phone_verification\",\n",
    "   \"rt_few_days\",\"rt_within_day\",\"rt_few_hours\",\"rt_within_hours\",\"location_ballard\",\"location_beacon_hill\",\"location_capital_hill\",\n",
    "   \"location_cascade\",\"location_central_area\",\"location_delridge\",\"location_downtown\",\"location_interbay\",\"location_lake_city\",\"location_magnolia\",\n",
    "   \"location_northgate\",\"location_other\",\"location_queen_anne\",\"location_rainier_vally\",\"location_seward_park\",\"location_university_district\",\n",
    "   \"location_west_seattle\",\"pt_apartment\",\"pt_b&b\",\"pt_boat\",\"pt_bungalow\",\"pt_cabin\",\"pt_rv\",\"pt_chalet\",\"pt_condo\",\"pt_dorm\",\"pt_house\",\"pt_loft\",\n",
    "   \"pt_other\",\"pt_tent\",\"pt_townhouse\",\"pt_treehouse\",\"pt_yurt\",\"rt_entire_home\",\"rt_private_room\",\"rt_shared_room\",\"bt_air_bed\",\"bt_couch\",\n",
    "   \"bt_futon\",\"bt_pull_out_sofa\",\"bt_real_bed\",\"cp_flexible\",\"cp_moderate\",\"cp_strict\"\n",
    "]\n",
    "\n",
    "# columns = [\n",
    "# \"id\",\"host_id\",\"booking_id\",\"name\",\"neighbourhood_group\",\"city\",\"state\",\"zipcode\",\"latitude\",\"longitude\",\"property_type\",\"room_type\",\n",
    "# \"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\"bed_type\",\"instant_bookable\",\"cancellation_policy\",\"require_guest_profile_picture\",\"require_guest_phone_verification\",\n",
    "# \"number_of_reviews\",\"first_review\",\"last_review\",\"review_scores_rating\",\"review_scores_accuracy\",\"review_scores_cleanliness\",\"review_scores_checkin\",\"review_scores_communication\",\n",
    "# \"review_scores_location\",\"review_scores_value\",\"reviews_per_month\",\"host_name\",\"host_since\",\"host_listings_count\",\"host_location\",\"host_response_time\",\"host_response_rate\",\n",
    "# \"host_acceptance_rate\",\"host_is_superhost\",\"host_has_profile_pic\",\"host_identity_verified\",\"rating_good_or_bad\",\"num_of_reivews_gt_avg\",\"num_of_accom_gt_avg\",\n",
    "# \"num_of_bedrooms_gt_avg\",\"num_of_beds_gt_avg\",\"num_of_baths_gt_avg\",\"response_rate_gt_avg\",\"accept_rate_gt_avg\",\"accept_rate_below_avg\",\"accept_rate_above_avg\",\n",
    "# \"response_rate_below_avg\",\"response_rate_above_avg\",\"below_avg_num_of_reviews\",\"above_avg_num_of_reviews\",\"below_avg_num_of_accom\",\"above_avg_num_of_accom\",\n",
    "# \"below_avg_num_of_bedrooms\",\"above_avg_num_of_bedrooms\",\"below_avg_num_of_beds\",\"above_avg_num_of_beds\",\"below_avg_num_of_baths\",\"above_avg_num_of_baths\",\n",
    "# \"not_a_superhost\",\"a_superhost\",\"host_does_not_have_profile_pic\",\"host_does_have_profile_pic\",\"host_does_not_have_identity_ver\",\"host_does_have_identity_ver\",\n",
    "# \"not_instantly_bookable\",\"instantly_bookable\",\"does_not_require_guest_prof_pic\",\"requires_guest_profile_pic\",\"does_not_require_guest_phone_verification\",\n",
    "# \"requires_guest_phone_verification\",\"rt_few_days\",\"rt_within_day\",\"rt_few_hours\",\"rt_within_hours\",\"location_ballard\",\"location_beacon_hill\",\"location_capital_hill\",\n",
    "# \"location_cascade\",\"location_central_area\",\"location_delridge\",\"location_downtown\",\"location_interbay\",\"location_lake_city\",\"location_magnolia\",\"location_northgate\",\n",
    "# \"location_other\",\"location_queen_anne\",\"location_rainier_vally\",\"location_seward_park\",\"location_university_district\",\"location_west_seattle\",\"pt_apartment\",\n",
    "# \"pt_b&b\",\"pt_boat\",\"pt_bungalow\",\"pt_cabin\",\"pt_rv\",\"pt_chalet\",\"pt_condo\",\"pt_dorm\",\"pt_house\",\"pt_loft\",\"pt_other\",\"pt_tent\",\"pt_townhouse\",\"pt_treehouse\",\n",
    "# \"pt_yurt\",\"rt_entire_home\",\"rt_private_room\",\"rt_shared_room\",\"bt_air_bed\",\"bt_couch\",\"bt_futon\",\"bt_pull_out_sofa\",\"bt_real_bed\",\"cp_flexible\",\"cp_moderate\",\"cp_strict\"\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_good_or_bad</th>\n",
       "      <th>accept_rate_below_avg</th>\n",
       "      <th>accept_rate_above_avg</th>\n",
       "      <th>response_rate_below_avg</th>\n",
       "      <th>response_rate_above_avg</th>\n",
       "      <th>below_avg_num_of_reviews</th>\n",
       "      <th>above_avg_num_of_reviews</th>\n",
       "      <th>below_avg_num_of_accom</th>\n",
       "      <th>above_avg_num_of_accom</th>\n",
       "      <th>below_avg_num_of_bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>rt_private_room</th>\n",
       "      <th>rt_shared_room</th>\n",
       "      <th>bt_air_bed</th>\n",
       "      <th>bt_couch</th>\n",
       "      <th>bt_futon</th>\n",
       "      <th>bt_pull_out_sofa</th>\n",
       "      <th>bt_real_bed</th>\n",
       "      <th>cp_flexible</th>\n",
       "      <th>cp_moderate</th>\n",
       "      <th>cp_strict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating_good_or_bad  accept_rate_below_avg  accept_rate_above_avg  \\\n",
       "0        good_review                    0.0                    1.0   \n",
       "1        good_review                    0.0                    1.0   \n",
       "2        good_review                    0.0                    1.0   \n",
       "3         bad_review                    0.0                    1.0   \n",
       "4        good_review                    0.0                    1.0   \n",
       "\n",
       "   response_rate_below_avg  response_rate_above_avg  below_avg_num_of_reviews  \\\n",
       "0                      0.0                      1.0                       0.0   \n",
       "1                      0.0                      1.0                       1.0   \n",
       "2                      0.0                      1.0                       1.0   \n",
       "3                      0.0                      1.0                       1.0   \n",
       "4                      0.0                      1.0                       1.0   \n",
       "\n",
       "   above_avg_num_of_reviews  below_avg_num_of_accom  above_avg_num_of_accom  \\\n",
       "0                       1.0                     1.0                     0.0   \n",
       "1                       0.0                     1.0                     0.0   \n",
       "2                       0.0                     1.0                     0.0   \n",
       "3                       0.0                     1.0                     0.0   \n",
       "4                       0.0                     1.0                     0.0   \n",
       "\n",
       "   below_avg_num_of_bedrooms  ...  rt_private_room  rt_shared_room  \\\n",
       "0                        1.0  ...              0.0             1.0   \n",
       "1                        1.0  ...              0.0             1.0   \n",
       "2                        1.0  ...              1.0             0.0   \n",
       "3                        1.0  ...              0.0             1.0   \n",
       "4                        1.0  ...              1.0             0.0   \n",
       "\n",
       "   bt_air_bed  bt_couch  bt_futon  bt_pull_out_sofa  bt_real_bed  cp_flexible  \\\n",
       "0         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "1         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "2         0.0       0.0       0.0               0.0          1.0          0.0   \n",
       "3         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "4         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "\n",
       "   cp_moderate  cp_strict  \n",
       "0          0.0        1.0  \n",
       "1          0.0        1.0  \n",
       "2          0.0        1.0  \n",
       "3          0.0        1.0  \n",
       "4          0.0        1.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('ml_final_data.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# convert interest rate to numerical\n",
    "# df['host_response_rate'] = df['host_response_rate'].str.replace('%', '')\n",
    "# df['host_response_rate'] = df['host_response_rate'].astype('float') / 100\n",
    "# df['host_acceptance_rate'] = df['host_acceptance_rate'].str.replace('%', '')\n",
    "# df['host_acceptance_rate'] = df['host_acceptance_rate'].astype('float') / 100\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept_rate_below_avg</th>\n",
       "      <th>accept_rate_above_avg</th>\n",
       "      <th>response_rate_below_avg</th>\n",
       "      <th>response_rate_above_avg</th>\n",
       "      <th>below_avg_num_of_reviews</th>\n",
       "      <th>above_avg_num_of_reviews</th>\n",
       "      <th>below_avg_num_of_accom</th>\n",
       "      <th>above_avg_num_of_accom</th>\n",
       "      <th>below_avg_num_of_bedrooms</th>\n",
       "      <th>above_avg_num_of_bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>rt_shared_room</th>\n",
       "      <th>bt_air_bed</th>\n",
       "      <th>bt_couch</th>\n",
       "      <th>bt_futon</th>\n",
       "      <th>bt_pull_out_sofa</th>\n",
       "      <th>bt_real_bed</th>\n",
       "      <th>cp_flexible</th>\n",
       "      <th>cp_moderate</th>\n",
       "      <th>cp_strict</th>\n",
       "      <th>score_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accept_rate_below_avg  accept_rate_above_avg  response_rate_below_avg  \\\n",
       "0                    0.0                    1.0                      0.0   \n",
       "1                    0.0                    1.0                      0.0   \n",
       "2                    0.0                    1.0                      0.0   \n",
       "3                    0.0                    1.0                      0.0   \n",
       "4                    0.0                    1.0                      0.0   \n",
       "\n",
       "   response_rate_above_avg  below_avg_num_of_reviews  \\\n",
       "0                      1.0                       0.0   \n",
       "1                      1.0                       1.0   \n",
       "2                      1.0                       1.0   \n",
       "3                      1.0                       1.0   \n",
       "4                      1.0                       1.0   \n",
       "\n",
       "   above_avg_num_of_reviews  below_avg_num_of_accom  above_avg_num_of_accom  \\\n",
       "0                       1.0                     1.0                     0.0   \n",
       "1                       0.0                     1.0                     0.0   \n",
       "2                       0.0                     1.0                     0.0   \n",
       "3                       0.0                     1.0                     0.0   \n",
       "4                       0.0                     1.0                     0.0   \n",
       "\n",
       "   below_avg_num_of_bedrooms  above_avg_num_of_bedrooms  ...  rt_shared_room  \\\n",
       "0                        1.0                        0.0  ...             1.0   \n",
       "1                        1.0                        0.0  ...             1.0   \n",
       "2                        1.0                        0.0  ...             0.0   \n",
       "3                        1.0                        0.0  ...             1.0   \n",
       "4                        1.0                        0.0  ...             0.0   \n",
       "\n",
       "   bt_air_bed  bt_couch  bt_futon  bt_pull_out_sofa  bt_real_bed  cp_flexible  \\\n",
       "0         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "1         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "2         0.0       0.0       0.0               0.0          1.0          0.0   \n",
       "3         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "4         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "\n",
       "   cp_moderate  cp_strict  score_cutoff  \n",
       "0          0.0        1.0             1  \n",
       "1          0.0        1.0             1  \n",
       "2          0.0        1.0             1  \n",
       "3          0.0        1.0             0  \n",
       "4          0.0        1.0             1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (df['rating_good_or_bad'] == 'bad_review'),\n",
    "    (df['rating_good_or_bad'] >= 'good_review')]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [0, 1,]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['score_cutoff'] = np.select(conditions, values)\n",
    "\n",
    "df = df.drop([\"rating_good_or_bad\"], axis=1)\n",
    "\n",
    "# display updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2462\n",
       "0     189\n",
       "Name: score_cutoff, dtype: int64"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check review scores\n",
    "review_scores = df['score_cutoff'].value_counts()\n",
    "review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Try out a neural network\n",
    "# Split our preprocessed data into our features and target arrays(training and testing)\n",
    "y = df[\"score_cutoff\"].values\n",
    "X = df.drop([\"score_cutoff\"], axis = 1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance.  Must scale after trian and test has been established.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_67 (Dense)            (None, 7)                 525       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 9)                 72        \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 7)                 42        \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 7\n",
    "hidden_nodes_layer2 = 9\n",
    "hidden_nodes_layer3 = 9\n",
    "hidden_nodes_layer4 = 5\n",
    "hidden_nodes_layer5 = 7\n",
    "hidden_nodes_layer6 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "\n",
    "# third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "# forth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"tanh\"))\n",
    "\n",
    "# fifth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"tanh\"))\n",
    "\n",
    "# 6th hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6059 - accuracy: 0.8129\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.9281\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2631 - accuracy: 0.9316\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2367 - accuracy: 0.9336\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.9371\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9371\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.9356\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.9386\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.9376\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.9381\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.9381\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.9381\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9422\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.9432\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.9427\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 988us/step - loss: 0.1815 - accuracy: 0.9422\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.9422\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.9396\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.9427\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1752 - accuracy: 0.9427\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.9422\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9472\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.1712 - accuracy: 0.9467\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.9477\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9487\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.9452\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1660 - accuracy: 0.9467\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9487\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9472\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.9477\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1638 - accuracy: 0.9457\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9487\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1627 - accuracy: 0.9487\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1568 - accuracy: 0.9492\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1654 - accuracy: 0.9452\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1573 - accuracy: 0.9502\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.1558 - accuracy: 0.9507\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 985us/step - loss: 0.1558 - accuracy: 0.9477\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 979us/step - loss: 0.1567 - accuracy: 0.9497\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 962us/step - loss: 0.1550 - accuracy: 0.9507\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1537 - accuracy: 0.9492\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.1500 - accuracy: 0.9497\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 978us/step - loss: 0.1560 - accuracy: 0.9477\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 987us/step - loss: 0.1531 - accuracy: 0.9487\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 931us/step - loss: 0.1511 - accuracy: 0.9482\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 988us/step - loss: 0.1483 - accuracy: 0.9512\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 975us/step - loss: 0.1500 - accuracy: 0.9497\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 991us/step - loss: 0.1532 - accuracy: 0.9472\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 952us/step - loss: 0.1460 - accuracy: 0.9497\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 944us/step - loss: 0.1501 - accuracy: 0.9517\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_fit = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.2970 - accuracy: 0.9140 - 133ms/epoch - 6ms/step\n",
      "Loss: 0.2970286011695862, Accuracy: 0.9140271544456482\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "##nn.save(\"model\")\n",
    "##nn.save(\"model2.h5\")\n",
    "#df.to_csv('input_test.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 669us/step\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# 2. Pre-process the data\n",
    "# (Assuming the pre-processing steps are the same as for the training and testing data)\n",
    "\n",
    "# 3. Make predictions\n",
    "predictions = nn.predict(df2)\n",
    "\n",
    "rounded_predictions = np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the predictions and set its index to be the same as the input DataFrame\n",
    "predictions_df = pd.DataFrame(rounded_predictions, index=df2.index, columns=[\"Prediction\"])\n",
    "\n",
    "# Merge the predictions_df back to the original df\n",
    "merged_df = pd.concat([df2, predictions_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept_rate_below_avg</th>\n",
       "      <th>accept_rate_above_avg</th>\n",
       "      <th>response_rate_below_avg</th>\n",
       "      <th>response_rate_above_avg</th>\n",
       "      <th>below_avg_num_of_reviews</th>\n",
       "      <th>above_avg_num_of_reviews</th>\n",
       "      <th>below_avg_num_of_accom</th>\n",
       "      <th>above_avg_num_of_accom</th>\n",
       "      <th>below_avg_num_of_bedrooms</th>\n",
       "      <th>above_avg_num_of_bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>rt_shared_room</th>\n",
       "      <th>bt_air_bed</th>\n",
       "      <th>bt_couch</th>\n",
       "      <th>bt_futon</th>\n",
       "      <th>bt_pull_out_sofa</th>\n",
       "      <th>bt_real_bed</th>\n",
       "      <th>cp_flexible</th>\n",
       "      <th>cp_moderate</th>\n",
       "      <th>cp_strict</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accept_rate_below_avg  accept_rate_above_avg  response_rate_below_avg  \\\n",
       "0                      0                      1                        0   \n",
       "1                      0                      1                        0   \n",
       "2                      0                      1                        0   \n",
       "3                      0                      1                        0   \n",
       "4                      0                      1                        0   \n",
       "\n",
       "   response_rate_above_avg  below_avg_num_of_reviews  \\\n",
       "0                        1                         0   \n",
       "1                        1                         1   \n",
       "2                        1                         1   \n",
       "3                        1                         1   \n",
       "4                        1                         1   \n",
       "\n",
       "   above_avg_num_of_reviews  below_avg_num_of_accom  above_avg_num_of_accom  \\\n",
       "0                         1                       1                       0   \n",
       "1                         0                       1                       0   \n",
       "2                         0                       1                       0   \n",
       "3                         0                       1                       0   \n",
       "4                         0                       1                       0   \n",
       "\n",
       "   below_avg_num_of_bedrooms  above_avg_num_of_bedrooms  ...  rt_shared_room  \\\n",
       "0                          1                          0  ...               1   \n",
       "1                          1                          0  ...               1   \n",
       "2                          1                          0  ...               0   \n",
       "3                          1                          0  ...               1   \n",
       "4                          1                          0  ...               0   \n",
       "\n",
       "   bt_air_bed  bt_couch  bt_futon  bt_pull_out_sofa  bt_real_bed  cp_flexible  \\\n",
       "0           0         0         1                 0            0            0   \n",
       "1           0         0         1                 0            0            0   \n",
       "2           0         0         0                 0            1            0   \n",
       "3           0         0         1                 0            0            0   \n",
       "4           0         0         1                 0            0            0   \n",
       "\n",
       "   cp_moderate  cp_strict  Prediction  \n",
       "0            0          1         1.0  \n",
       "1            0          1         1.0  \n",
       "2            0          1         1.0  \n",
       "3            0          1         1.0  \n",
       "4            0          1         1.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('results.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86969af4118fd2beaee010b14a97d3c8fe7dc31ff55f1528eea7eaecb45368d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
