{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "   \"rating_good_or_bad\",\"accept_rate_below_avg\",\"accept_rate_above_avg\",\"response_rate_below_avg\",\"response_rate_above_avg\",\"below_avg_num_of_reviews\",\n",
    "   \"above_avg_num_of_reviews\",\"below_avg_num_of_accom\",\"above_avg_num_of_accom\",\"below_avg_num_of_bedrooms\",\"above_avg_num_of_bedrooms\",\"below_avg_num_of_beds\",\n",
    "   \"above_avg_num_of_beds\",\"below_avg_num_of_baths\",\"above_avg_num_of_baths\",\"not_a_superhost\",\"a_superhost\",\"host_does_not_have_profile_pic\",\n",
    "   \"host_does_have_profile_pic\",\"host_does_not_have_identity_ver\",\"host_does_have_identity_ver\",\"not_instantly_bookable\",\"instantly_bookable\",\n",
    "   \"does_not_require_guest_prof_pic\",\"requires_guest_profile_pic\",\"does_not_require_guest_phone_verification\",\"requires_guest_phone_verification\",\n",
    "   \"rt_few_days\",\"rt_within_day\",\"rt_few_hours\",\"rt_within_hours\",\"location_ballard\",\"location_beacon_hill\",\"location_capital_hill\",\n",
    "   \"location_cascade\",\"location_central_area\",\"location_delridge\",\"location_downtown\",\"location_interbay\",\"location_lake_city\",\"location_magnolia\",\n",
    "   \"location_northgate\",\"location_other\",\"location_queen_anne\",\"location_rainier_vally\",\"location_seward_park\",\"location_university_district\",\n",
    "   \"location_west_seattle\",\"pt_apartment\",\"pt_b&b\",\"pt_boat\",\"pt_bungalow\",\"pt_cabin\",\"pt_rv\",\"pt_chalet\",\"pt_condo\",\"pt_dorm\",\"pt_house\",\"pt_loft\",\n",
    "   \"pt_other\",\"pt_tent\",\"pt_townhouse\",\"pt_treehouse\",\"pt_yurt\",\"rt_entire_home\",\"rt_private_room\",\"rt_shared_room\",\"bt_air_bed\",\"bt_couch\",\n",
    "   \"bt_futon\",\"bt_pull_out_sofa\",\"bt_real_bed\",\"cp_flexible\",\"cp_moderate\",\"cp_strict\"\n",
    "]\n",
    "\n",
    "# columns = [\n",
    "# \"id\",\"host_id\",\"booking_id\",\"name\",\"neighbourhood_group\",\"city\",\"state\",\"zipcode\",\"latitude\",\"longitude\",\"property_type\",\"room_type\",\n",
    "# \"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\"bed_type\",\"instant_bookable\",\"cancellation_policy\",\"require_guest_profile_picture\",\"require_guest_phone_verification\",\n",
    "# \"number_of_reviews\",\"first_review\",\"last_review\",\"review_scores_rating\",\"review_scores_accuracy\",\"review_scores_cleanliness\",\"review_scores_checkin\",\"review_scores_communication\",\n",
    "# \"review_scores_location\",\"review_scores_value\",\"reviews_per_month\",\"host_name\",\"host_since\",\"host_listings_count\",\"host_location\",\"host_response_time\",\"host_response_rate\",\n",
    "# \"host_acceptance_rate\",\"host_is_superhost\",\"host_has_profile_pic\",\"host_identity_verified\",\"rating_good_or_bad\",\"num_of_reivews_gt_avg\",\"num_of_accom_gt_avg\",\n",
    "# \"num_of_bedrooms_gt_avg\",\"num_of_beds_gt_avg\",\"num_of_baths_gt_avg\",\"response_rate_gt_avg\",\"accept_rate_gt_avg\",\"accept_rate_below_avg\",\"accept_rate_above_avg\",\n",
    "# \"response_rate_below_avg\",\"response_rate_above_avg\",\"below_avg_num_of_reviews\",\"above_avg_num_of_reviews\",\"below_avg_num_of_accom\",\"above_avg_num_of_accom\",\n",
    "# \"below_avg_num_of_bedrooms\",\"above_avg_num_of_bedrooms\",\"below_avg_num_of_beds\",\"above_avg_num_of_beds\",\"below_avg_num_of_baths\",\"above_avg_num_of_baths\",\n",
    "# \"not_a_superhost\",\"a_superhost\",\"host_does_not_have_profile_pic\",\"host_does_have_profile_pic\",\"host_does_not_have_identity_ver\",\"host_does_have_identity_ver\",\n",
    "# \"not_instantly_bookable\",\"instantly_bookable\",\"does_not_require_guest_prof_pic\",\"requires_guest_profile_pic\",\"does_not_require_guest_phone_verification\",\n",
    "# \"requires_guest_phone_verification\",\"rt_few_days\",\"rt_within_day\",\"rt_few_hours\",\"rt_within_hours\",\"location_ballard\",\"location_beacon_hill\",\"location_capital_hill\",\n",
    "# \"location_cascade\",\"location_central_area\",\"location_delridge\",\"location_downtown\",\"location_interbay\",\"location_lake_city\",\"location_magnolia\",\"location_northgate\",\n",
    "# \"location_other\",\"location_queen_anne\",\"location_rainier_vally\",\"location_seward_park\",\"location_university_district\",\"location_west_seattle\",\"pt_apartment\",\n",
    "# \"pt_b&b\",\"pt_boat\",\"pt_bungalow\",\"pt_cabin\",\"pt_rv\",\"pt_chalet\",\"pt_condo\",\"pt_dorm\",\"pt_house\",\"pt_loft\",\"pt_other\",\"pt_tent\",\"pt_townhouse\",\"pt_treehouse\",\n",
    "# \"pt_yurt\",\"rt_entire_home\",\"rt_private_room\",\"rt_shared_room\",\"bt_air_bed\",\"bt_couch\",\"bt_futon\",\"bt_pull_out_sofa\",\"bt_real_bed\",\"cp_flexible\",\"cp_moderate\",\"cp_strict\"\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_good_or_bad</th>\n",
       "      <th>accept_rate_below_avg</th>\n",
       "      <th>accept_rate_above_avg</th>\n",
       "      <th>response_rate_below_avg</th>\n",
       "      <th>response_rate_above_avg</th>\n",
       "      <th>below_avg_num_of_reviews</th>\n",
       "      <th>above_avg_num_of_reviews</th>\n",
       "      <th>below_avg_num_of_accom</th>\n",
       "      <th>above_avg_num_of_accom</th>\n",
       "      <th>below_avg_num_of_bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>rt_private_room</th>\n",
       "      <th>rt_shared_room</th>\n",
       "      <th>bt_air_bed</th>\n",
       "      <th>bt_couch</th>\n",
       "      <th>bt_futon</th>\n",
       "      <th>bt_pull_out_sofa</th>\n",
       "      <th>bt_real_bed</th>\n",
       "      <th>cp_flexible</th>\n",
       "      <th>cp_moderate</th>\n",
       "      <th>cp_strict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good_review</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  rating_good_or_bad  accept_rate_below_avg  accept_rate_above_avg  \\\n",
       "0        good_review                    0.0                    1.0   \n",
       "1        good_review                    0.0                    1.0   \n",
       "2        good_review                    0.0                    1.0   \n",
       "3         bad_review                    0.0                    1.0   \n",
       "4        good_review                    0.0                    1.0   \n",
       "\n",
       "   response_rate_below_avg  response_rate_above_avg  below_avg_num_of_reviews  \\\n",
       "0                      0.0                      1.0                       0.0   \n",
       "1                      0.0                      1.0                       1.0   \n",
       "2                      0.0                      1.0                       1.0   \n",
       "3                      0.0                      1.0                       1.0   \n",
       "4                      0.0                      1.0                       1.0   \n",
       "\n",
       "   above_avg_num_of_reviews  below_avg_num_of_accom  above_avg_num_of_accom  \\\n",
       "0                       1.0                     1.0                     0.0   \n",
       "1                       0.0                     1.0                     0.0   \n",
       "2                       0.0                     1.0                     0.0   \n",
       "3                       0.0                     1.0                     0.0   \n",
       "4                       0.0                     1.0                     0.0   \n",
       "\n",
       "   below_avg_num_of_bedrooms  ...  rt_private_room  rt_shared_room  \\\n",
       "0                        1.0  ...              0.0             1.0   \n",
       "1                        1.0  ...              0.0             1.0   \n",
       "2                        1.0  ...              1.0             0.0   \n",
       "3                        1.0  ...              0.0             1.0   \n",
       "4                        1.0  ...              1.0             0.0   \n",
       "\n",
       "   bt_air_bed  bt_couch  bt_futon  bt_pull_out_sofa  bt_real_bed  cp_flexible  \\\n",
       "0         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "1         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "2         0.0       0.0       0.0               0.0          1.0          0.0   \n",
       "3         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "4         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "\n",
       "   cp_moderate  cp_strict  \n",
       "0          0.0        1.0  \n",
       "1          0.0        1.0  \n",
       "2          0.0        1.0  \n",
       "3          0.0        1.0  \n",
       "4          0.0        1.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('ml_final_data.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# convert interest rate to numerical\n",
    "# df['host_response_rate'] = df['host_response_rate'].str.replace('%', '')\n",
    "# df['host_response_rate'] = df['host_response_rate'].astype('float') / 100\n",
    "# df['host_acceptance_rate'] = df['host_acceptance_rate'].str.replace('%', '')\n",
    "# df['host_acceptance_rate'] = df['host_acceptance_rate'].astype('float') / 100\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept_rate_below_avg</th>\n",
       "      <th>accept_rate_above_avg</th>\n",
       "      <th>response_rate_below_avg</th>\n",
       "      <th>response_rate_above_avg</th>\n",
       "      <th>below_avg_num_of_reviews</th>\n",
       "      <th>above_avg_num_of_reviews</th>\n",
       "      <th>below_avg_num_of_accom</th>\n",
       "      <th>above_avg_num_of_accom</th>\n",
       "      <th>below_avg_num_of_bedrooms</th>\n",
       "      <th>above_avg_num_of_bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>rt_shared_room</th>\n",
       "      <th>bt_air_bed</th>\n",
       "      <th>bt_couch</th>\n",
       "      <th>bt_futon</th>\n",
       "      <th>bt_pull_out_sofa</th>\n",
       "      <th>bt_real_bed</th>\n",
       "      <th>cp_flexible</th>\n",
       "      <th>cp_moderate</th>\n",
       "      <th>cp_strict</th>\n",
       "      <th>score_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accept_rate_below_avg  accept_rate_above_avg  response_rate_below_avg  \\\n",
       "0                    0.0                    1.0                      0.0   \n",
       "1                    0.0                    1.0                      0.0   \n",
       "2                    0.0                    1.0                      0.0   \n",
       "3                    0.0                    1.0                      0.0   \n",
       "4                    0.0                    1.0                      0.0   \n",
       "\n",
       "   response_rate_above_avg  below_avg_num_of_reviews  \\\n",
       "0                      1.0                       0.0   \n",
       "1                      1.0                       1.0   \n",
       "2                      1.0                       1.0   \n",
       "3                      1.0                       1.0   \n",
       "4                      1.0                       1.0   \n",
       "\n",
       "   above_avg_num_of_reviews  below_avg_num_of_accom  above_avg_num_of_accom  \\\n",
       "0                       1.0                     1.0                     0.0   \n",
       "1                       0.0                     1.0                     0.0   \n",
       "2                       0.0                     1.0                     0.0   \n",
       "3                       0.0                     1.0                     0.0   \n",
       "4                       0.0                     1.0                     0.0   \n",
       "\n",
       "   below_avg_num_of_bedrooms  above_avg_num_of_bedrooms  ...  rt_shared_room  \\\n",
       "0                        1.0                        0.0  ...             1.0   \n",
       "1                        1.0                        0.0  ...             1.0   \n",
       "2                        1.0                        0.0  ...             0.0   \n",
       "3                        1.0                        0.0  ...             1.0   \n",
       "4                        1.0                        0.0  ...             0.0   \n",
       "\n",
       "   bt_air_bed  bt_couch  bt_futon  bt_pull_out_sofa  bt_real_bed  cp_flexible  \\\n",
       "0         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "1         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "2         0.0       0.0       0.0               0.0          1.0          0.0   \n",
       "3         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "4         0.0       0.0       1.0               0.0          0.0          0.0   \n",
       "\n",
       "   cp_moderate  cp_strict  score_cutoff  \n",
       "0          0.0        1.0             1  \n",
       "1          0.0        1.0             1  \n",
       "2          0.0        1.0             1  \n",
       "3          0.0        1.0             0  \n",
       "4          0.0        1.0             1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = [\n",
    "    (df['rating_good_or_bad'] == 'bad_review'),\n",
    "    (df['rating_good_or_bad'] >= 'good_review')]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [0, 1,]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df['score_cutoff'] = np.select(conditions, values)\n",
    "\n",
    "df = df.drop([\"rating_good_or_bad\"], axis=1)\n",
    "\n",
    "# display updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2462\n",
       "0     189\n",
       "Name: score_cutoff, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check review scores\n",
    "review_scores = df['score_cutoff'].value_counts()\n",
    "review_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Try out a neural network\n",
    "# Split our preprocessed data into our features and target arrays(training and testing)\n",
    "y = df[\"score_cutoff\"].values\n",
    "X = df.drop([\"score_cutoff\"], axis = 1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "\n",
    "print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance.  Must scale after trian and test has been established.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 7)                 525       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 9)                 72        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 7)                 42        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 = 7\n",
    "hidden_nodes_layer2 = 9\n",
    "hidden_nodes_layer3 = 9\n",
    "hidden_nodes_layer4 = 5\n",
    "hidden_nodes_layer5 = 7\n",
    "hidden_nodes_layer6 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "\n",
    "# third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "# forth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer4, activation=\"tanh\"))\n",
    "\n",
    "# fifth hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer5, activation=\"tanh\"))\n",
    "\n",
    "# 6th hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer6, activation=\"tanh\"))\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.6952\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 0s 970us/step - loss: 0.4028 - accuracy: 0.8858\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.9286\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2551 - accuracy: 0.9311\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 0s 968us/step - loss: 0.2417 - accuracy: 0.9321\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 0s 956us/step - loss: 0.2330 - accuracy: 0.9346\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 0s 972us/step - loss: 0.2281 - accuracy: 0.9346\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 0s 935us/step - loss: 0.2231 - accuracy: 0.9366\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 0s 964us/step - loss: 0.2156 - accuracy: 0.9386\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9371\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9371\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.9386\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 0s 973us/step - loss: 0.2043 - accuracy: 0.9406\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 0s 927us/step - loss: 0.2023 - accuracy: 0.9411\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9391\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.9371\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9416\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.9437\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 0s 981us/step - loss: 0.1939 - accuracy: 0.9427\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.9411\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9442\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9432\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9432\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.9427\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.9422\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 0s 992us/step - loss: 0.1831 - accuracy: 0.9447\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 0s 971us/step - loss: 0.1799 - accuracy: 0.9457\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 0s 968us/step - loss: 0.1787 - accuracy: 0.9457\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.9447\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.9442\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.9457\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 0s 950us/step - loss: 0.1718 - accuracy: 0.9507\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9462\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9472\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 0s 974us/step - loss: 0.1737 - accuracy: 0.9487\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9502\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 0s 958us/step - loss: 0.1666 - accuracy: 0.9487\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 0s 911us/step - loss: 0.1636 - accuracy: 0.9532\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 0s 941us/step - loss: 0.1636 - accuracy: 0.9522\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 0s 931us/step - loss: 0.1642 - accuracy: 0.9517\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 0s 936us/step - loss: 0.1635 - accuracy: 0.9507\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 0s 917us/step - loss: 0.1615 - accuracy: 0.9502\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 0s 952us/step - loss: 0.1655 - accuracy: 0.9492\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 0s 942us/step - loss: 0.1606 - accuracy: 0.9517\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 0s 941us/step - loss: 0.1598 - accuracy: 0.9512\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 0s 958us/step - loss: 0.1595 - accuracy: 0.9522\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 0s 950us/step - loss: 0.1575 - accuracy: 0.9532\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 0s 949us/step - loss: 0.1567 - accuracy: 0.9537\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 0s 962us/step - loss: 0.1641 - accuracy: 0.9467\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 0s 950us/step - loss: 0.1619 - accuracy: 0.9527\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_fit = nn.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.3142 - accuracy: 0.8989 - 122ms/epoch - 6ms/step\n",
      "Loss: 0.314196914434433, Accuracy: 0.8989441990852356\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    }
   ],
   "source": [
    "nn.save(\"model\")\n",
    "nn.save(\"model2.h5\")\n",
    "df.to_csv('input_test.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= nn.predict(x=X_test, batch_size=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9826272]\n",
      "[0.923408]\n",
      "[0.98323274]\n",
      "[0.98408526]\n",
      "[0.97999847]\n",
      "[0.9814517]\n",
      "[0.9841668]\n",
      "[0.9834918]\n",
      "[0.9841709]\n",
      "[0.9807275]\n",
      "[0.98048234]\n",
      "[0.9828599]\n",
      "[0.9831507]\n",
      "[0.9808882]\n",
      "[0.9796637]\n",
      "[0.98349786]\n",
      "[0.9820031]\n",
      "[0.89310175]\n",
      "[0.98204386]\n",
      "[0.9836436]\n",
      "[0.9806873]\n",
      "[0.98326945]\n",
      "[0.9842224]\n",
      "[0.97650534]\n",
      "[0.98064286]\n",
      "[0.9798344]\n",
      "[0.9803288]\n",
      "[0.983953]\n",
      "[0.97673947]\n",
      "[0.98331624]\n",
      "[0.9801063]\n",
      "[0.9826261]\n",
      "[0.97879213]\n",
      "[0.9803833]\n",
      "[0.97830606]\n",
      "[0.98163956]\n",
      "[0.9792345]\n",
      "[0.9839055]\n",
      "[0.94254494]\n",
      "[0.98312]\n",
      "[0.969061]\n",
      "[0.9821326]\n",
      "[0.96862584]\n",
      "[0.97586226]\n",
      "[0.9785726]\n",
      "[0.9830523]\n",
      "[0.96775675]\n",
      "[0.95917934]\n",
      "[0.9818829]\n",
      "[0.9828939]\n",
      "[0.98244274]\n",
      "[0.9832658]\n",
      "[0.9815876]\n",
      "[0.9822831]\n",
      "[0.98289186]\n",
      "[0.9834255]\n",
      "[0.98075116]\n",
      "[0.98315954]\n",
      "[0.9546074]\n",
      "[0.9811369]\n",
      "[0.98376304]\n",
      "[0.97286135]\n",
      "[0.98297554]\n",
      "[0.97943676]\n",
      "[0.94778323]\n",
      "[0.98321533]\n",
      "[0.98307705]\n",
      "[0.9832158]\n",
      "[0.9552157]\n",
      "[0.9829406]\n",
      "[0.9834497]\n",
      "[0.9793574]\n",
      "[0.9840774]\n",
      "[0.9786835]\n",
      "[0.9761433]\n",
      "[0.9762109]\n",
      "[0.98290944]\n",
      "[0.9687697]\n",
      "[0.9636018]\n",
      "[0.9805534]\n",
      "[0.9499044]\n",
      "[0.9816104]\n",
      "[0.9503459]\n",
      "[0.9829332]\n",
      "[0.98206574]\n",
      "[0.98044336]\n",
      "[0.9816104]\n",
      "[0.96860135]\n",
      "[0.98381466]\n",
      "[0.983854]\n",
      "[0.9777408]\n",
      "[0.9830466]\n",
      "[0.98155874]\n",
      "[0.9774847]\n",
      "[0.9741328]\n",
      "[0.98253185]\n",
      "[0.9729349]\n",
      "[0.9797639]\n",
      "[0.9764236]\n",
      "[0.98299116]\n",
      "[0.97567767]\n",
      "[0.9824982]\n",
      "[0.98171705]\n",
      "[0.95697665]\n",
      "[0.9802188]\n",
      "[0.9759423]\n",
      "[0.97715634]\n",
      "[0.95984733]\n",
      "[0.97599536]\n",
      "[0.9635269]\n",
      "[0.98117733]\n",
      "[0.98078084]\n",
      "[0.98303837]\n",
      "[0.9795531]\n",
      "[0.96743226]\n",
      "[0.9775561]\n",
      "[0.9814891]\n",
      "[0.9548791]\n",
      "[0.98289007]\n",
      "[0.9765445]\n",
      "[0.98367983]\n",
      "[0.97847545]\n",
      "[0.9826534]\n",
      "[0.9834089]\n",
      "[0.9835941]\n",
      "[0.982948]\n",
      "[0.9784841]\n",
      "[0.97915936]\n",
      "[0.951276]\n",
      "[0.98176414]\n",
      "[0.951276]\n",
      "[0.97847545]\n",
      "[0.97175455]\n",
      "[0.98335797]\n",
      "[0.98167443]\n",
      "[0.9790258]\n",
      "[0.95230883]\n",
      "[0.97790414]\n",
      "[0.96342427]\n",
      "[0.98189825]\n",
      "[0.98368794]\n",
      "[0.98188925]\n",
      "[0.9785726]\n",
      "[0.98216295]\n",
      "[0.98360366]\n",
      "[0.98194516]\n",
      "[0.9826908]\n",
      "[0.9829697]\n",
      "[0.98409027]\n",
      "[0.9791584]\n",
      "[0.9836228]\n",
      "[0.98220724]\n",
      "[0.9835063]\n",
      "[0.9833241]\n",
      "[0.97410727]\n",
      "[0.97193354]\n",
      "[0.9808906]\n",
      "[0.9798693]\n",
      "[0.98379993]\n",
      "[0.9820191]\n",
      "[0.983058]\n",
      "[0.97644573]\n",
      "[0.98148775]\n",
      "[0.9801063]\n",
      "[0.97980046]\n",
      "[0.98312]\n",
      "[0.97777593]\n",
      "[0.9838864]\n",
      "[0.9835042]\n",
      "[0.980752]\n",
      "[0.93570155]\n",
      "[0.9806526]\n",
      "[0.9801063]\n",
      "[0.98005724]\n",
      "[0.8854746]\n",
      "[0.9842914]\n",
      "[0.9803598]\n",
      "[0.9801063]\n",
      "[0.9833903]\n",
      "[0.98246443]\n",
      "[0.98413086]\n",
      "[0.9801063]\n",
      "[0.9840797]\n",
      "[0.97025955]\n",
      "[0.9742512]\n",
      "[0.9841141]\n",
      "[0.97484416]\n",
      "[0.98376495]\n",
      "[0.959414]\n",
      "[0.979423]\n",
      "[0.983836]\n",
      "[0.98267883]\n",
      "[0.98140424]\n",
      "[0.97025955]\n",
      "[0.96603125]\n",
      "[0.9793464]\n",
      "[0.98421717]\n",
      "[0.97905654]\n",
      "[0.9644263]\n",
      "[0.98179233]\n",
      "[0.8469889]\n",
      "[0.9819995]\n",
      "[0.9796221]\n",
      "[0.951276]\n",
      "[0.9759423]\n",
      "[0.98426974]\n",
      "[0.984056]\n",
      "[0.9814389]\n",
      "[0.9778179]\n",
      "[0.98142093]\n",
      "[0.97898054]\n",
      "[0.9811963]\n",
      "[0.951276]\n",
      "[0.97695357]\n",
      "[0.9785726]\n",
      "[0.98037994]\n",
      "[0.9784841]\n",
      "[0.9818129]\n",
      "[0.97674054]\n",
      "[0.9832879]\n",
      "[0.97423977]\n",
      "[0.98406756]\n",
      "[0.6956435]\n",
      "[0.9839009]\n",
      "[0.9834182]\n",
      "[0.9772934]\n",
      "[0.9824982]\n",
      "[0.9831403]\n",
      "[0.86214614]\n",
      "[0.98305136]\n",
      "[0.97175455]\n",
      "[0.9840644]\n",
      "[0.980968]\n",
      "[0.98067164]\n",
      "[0.983455]\n",
      "[0.9811331]\n",
      "[0.9826406]\n",
      "[0.98061186]\n",
      "[0.9830681]\n",
      "[0.97832304]\n",
      "[0.95667493]\n",
      "[0.9801063]\n",
      "[0.9839212]\n",
      "[0.98196745]\n",
      "[0.98364717]\n",
      "[0.98222286]\n",
      "[0.9806366]\n",
      "[0.98335797]\n",
      "[0.9777817]\n",
      "[0.98313355]\n",
      "[0.98302233]\n",
      "[0.9810971]\n",
      "[0.98378193]\n",
      "[0.9795035]\n",
      "[0.9763858]\n",
      "[0.98037994]\n",
      "[0.98088723]\n",
      "[0.98005795]\n",
      "[0.97943676]\n",
      "[0.98372257]\n",
      "[0.9830133]\n",
      "[0.980047]\n",
      "[0.91080683]\n",
      "[0.98315865]\n",
      "[0.9728587]\n",
      "[0.9834643]\n",
      "[0.98232424]\n",
      "[0.9830085]\n",
      "[0.98017967]\n",
      "[0.98117733]\n",
      "[0.98084474]\n",
      "[0.98270446]\n",
      "[0.9424955]\n",
      "[0.9825724]\n",
      "[0.9510325]\n",
      "[0.98142093]\n",
      "[0.98179144]\n",
      "[0.9841469]\n",
      "[0.9792203]\n",
      "[0.98216003]\n",
      "[0.98022854]\n",
      "[0.9801063]\n",
      "[0.9710292]\n",
      "[0.98070204]\n",
      "[0.96783364]\n",
      "[0.980313]\n",
      "[0.9828809]\n",
      "[0.97552866]\n",
      "[0.9777408]\n",
      "[0.9830559]\n",
      "[0.98385715]\n",
      "[0.97930753]\n",
      "[0.98334366]\n",
      "[0.9834272]\n",
      "[0.9827352]\n",
      "[0.95761895]\n",
      "[0.9835531]\n",
      "[0.98418057]\n",
      "[0.9829697]\n",
      "[0.97778547]\n",
      "[0.98376316]\n",
      "[0.9834492]\n",
      "[0.97520745]\n",
      "[0.9819092]\n",
      "[0.98304516]\n",
      "[0.9483113]\n",
      "[0.9783601]\n",
      "[0.97242284]\n",
      "[0.9841469]\n",
      "[0.97221786]\n",
      "[0.98337394]\n",
      "[0.9829266]\n",
      "[0.9835777]\n",
      "[0.984292]\n",
      "[0.8724953]\n",
      "[0.9808477]\n",
      "[0.9792268]\n",
      "[0.9826398]\n",
      "[0.9706667]\n",
      "[0.9829316]\n",
      "[0.97671694]\n",
      "[0.9832997]\n",
      "[0.9818117]\n",
      "[0.98362744]\n",
      "[0.98192155]\n",
      "[0.9813423]\n",
      "[0.98339903]\n",
      "[0.9418663]\n",
      "[0.90758115]\n",
      "[0.96821475]\n",
      "[0.97422284]\n",
      "[0.98090905]\n",
      "[0.9840521]\n",
      "[0.9799783]\n",
      "[0.98315084]\n",
      "[0.979634]\n",
      "[0.9659247]\n",
      "[0.9840075]\n",
      "[0.9798693]\n",
      "[0.92063594]\n",
      "[0.9839055]\n",
      "[0.9828283]\n",
      "[0.98222286]\n",
      "[0.98180133]\n",
      "[0.982616]\n",
      "[0.951276]\n",
      "[0.981237]\n",
      "[0.98248166]\n",
      "[0.9818295]\n",
      "[0.9698207]\n",
      "[0.9838304]\n",
      "[0.96603125]\n",
      "[0.9828773]\n",
      "[0.974316]\n",
      "[0.98196745]\n",
      "[0.97720855]\n",
      "[0.9830231]\n",
      "[0.9223767]\n",
      "[0.97881496]\n",
      "[0.9831449]\n",
      "[0.9776214]\n",
      "[0.9814702]\n",
      "[0.96889615]\n",
      "[0.98332596]\n",
      "[0.84955585]\n",
      "[0.9792265]\n",
      "[0.9833598]\n",
      "[0.9829218]\n",
      "[0.9838503]\n",
      "[0.97646195]\n",
      "[0.9790258]\n",
      "[0.9817726]\n",
      "[0.9839589]\n",
      "[0.97903484]\n",
      "[0.9804851]\n",
      "[0.98118925]\n",
      "[0.98274416]\n",
      "[0.97877795]\n",
      "[0.9697761]\n",
      "[0.9739536]\n",
      "[0.98345554]\n",
      "[0.98337376]\n",
      "[0.9832363]\n",
      "[0.98327595]\n",
      "[0.98189306]\n",
      "[0.97535664]\n",
      "[0.98015046]\n",
      "[0.9347558]\n",
      "[0.98210484]\n",
      "[0.97162765]\n",
      "[0.9813785]\n",
      "[0.98206574]\n",
      "[0.9658113]\n",
      "[0.9787938]\n",
      "[0.9773408]\n",
      "[0.98156923]\n",
      "[0.9755172]\n",
      "[0.9837739]\n",
      "[0.98302865]\n",
      "[0.9629234]\n",
      "[0.9837271]\n",
      "[0.98005724]\n",
      "[0.9702723]\n",
      "[0.9696688]\n",
      "[0.9682929]\n",
      "[0.9835917]\n",
      "[0.9824248]\n",
      "[0.97161156]\n",
      "[0.98185885]\n",
      "[0.97940713]\n",
      "[0.97492397]\n",
      "[0.9840441]\n",
      "[0.9829667]\n",
      "[0.97555304]\n",
      "[0.976124]\n",
      "[0.98194975]\n",
      "[0.9719809]\n",
      "[0.9836138]\n",
      "[0.98117733]\n",
      "[0.9793973]\n",
      "[0.98333466]\n",
      "[0.98303366]\n",
      "[0.98069245]\n",
      "[0.9771297]\n",
      "[0.97832304]\n",
      "[0.9809702]\n",
      "[0.9829406]\n",
      "[0.97175455]\n",
      "[0.98252785]\n",
      "[0.9629234]\n",
      "[0.98038316]\n",
      "[0.98295313]\n",
      "[0.98352176]\n",
      "[0.9835393]\n",
      "[0.98404807]\n",
      "[0.9795035]\n",
      "[0.97812736]\n",
      "[0.98404115]\n",
      "[0.98085845]\n",
      "[0.9836361]\n",
      "[0.9838432]\n",
      "[0.97994214]\n",
      "[0.9811627]\n",
      "[0.9789902]\n",
      "[0.9807246]\n",
      "[0.98203117]\n",
      "[0.9778302]\n",
      "[0.9833395]\n",
      "[0.96498924]\n",
      "[0.9687697]\n",
      "[0.9769128]\n",
      "[0.9785726]\n",
      "[0.9820081]\n",
      "[0.9764496]\n",
      "[0.9796637]\n",
      "[0.98293364]\n",
      "[0.9801063]\n",
      "[0.80316615]\n",
      "[0.86214614]\n",
      "[0.9833544]\n",
      "[0.98355323]\n",
      "[0.9118116]\n",
      "[0.98364675]\n",
      "[0.98287416]\n",
      "[0.98221797]\n",
      "[0.97729665]\n",
      "[0.9791584]\n",
      "[0.9826107]\n",
      "[0.9829071]\n",
      "[0.9834819]\n",
      "[0.9793757]\n",
      "[0.93130696]\n",
      "[0.95690143]\n",
      "[0.98017454]\n",
      "[0.9796637]\n",
      "[0.9835556]\n",
      "[0.9348169]\n",
      "[0.98368603]\n",
      "[0.98169845]\n",
      "[0.98103404]\n",
      "[0.9833762]\n",
      "[0.9725157]\n",
      "[0.9843748]\n",
      "[0.9775412]\n",
      "[0.97861934]\n",
      "[0.9830527]\n",
      "[0.9764823]\n",
      "[0.98284304]\n",
      "[0.98264426]\n",
      "[0.97737396]\n",
      "[0.9839638]\n",
      "[0.9835404]\n",
      "[0.98068863]\n",
      "[0.97276056]\n",
      "[0.9828375]\n",
      "[0.97366244]\n",
      "[0.9575129]\n",
      "[0.9831865]\n",
      "[0.9808827]\n",
      "[0.97788405]\n",
      "[0.98330843]\n",
      "[0.97600955]\n",
      "[0.97423977]\n",
      "[0.98061186]\n",
      "[0.982106]\n",
      "[0.9629234]\n",
      "[0.97812843]\n",
      "[0.975243]\n",
      "[0.9664027]\n",
      "[0.9749671]\n",
      "[0.98373383]\n",
      "[0.96832365]\n",
      "[0.9820031]\n",
      "[0.97180516]\n",
      "[0.98243886]\n",
      "[0.9526733]\n",
      "[0.97542125]\n",
      "[0.97691333]\n",
      "[0.9838237]\n",
      "[0.9796637]\n",
      "[0.9837653]\n",
      "[0.9832599]\n",
      "[0.9826526]\n",
      "[0.9839378]\n",
      "[0.983436]\n",
      "[0.9801063]\n",
      "[0.98095095]\n",
      "[0.9807128]\n",
      "[0.9839055]\n",
      "[0.9839251]\n",
      "[0.9801063]\n",
      "[0.9834739]\n",
      "[0.9505254]\n",
      "[0.98053944]\n",
      "[0.9511792]\n",
      "[0.9808282]\n",
      "[0.9551638]\n",
      "[0.9837918]\n",
      "[0.94905174]\n",
      "[0.98204106]\n",
      "[0.98356164]\n",
      "[0.98067456]\n",
      "[0.88444555]\n",
      "[0.9801063]\n",
      "[0.8854746]\n",
      "[0.9781617]\n",
      "[0.98390275]\n",
      "[0.98307705]\n",
      "[0.9805749]\n",
      "[0.9823791]\n",
      "[0.9820998]\n",
      "[0.98421717]\n",
      "[0.984023]\n",
      "[0.98334605]\n",
      "[0.98345023]\n",
      "[0.9541891]\n",
      "[0.9837734]\n",
      "[0.9824714]\n",
      "[0.97960424]\n",
      "[0.9833649]\n",
      "[0.9841378]\n",
      "[0.98427695]\n",
      "[0.9793574]\n",
      "[0.984117]\n",
      "[0.981021]\n",
      "[0.98236144]\n",
      "[0.9803704]\n",
      "[0.97425616]\n",
      "[0.97980046]\n",
      "[0.9829396]\n",
      "[0.9805426]\n",
      "[0.9841469]\n",
      "[0.9794073]\n",
      "[0.9726531]\n",
      "[0.98268056]\n",
      "[0.9832324]\n",
      "[0.9805665]\n",
      "[0.9829406]\n",
      "[0.98379445]\n",
      "[0.9840601]\n",
      "[0.97950345]\n",
      "[0.96509695]\n",
      "[0.9830898]\n",
      "[0.9822299]\n",
      "[0.9832646]\n",
      "[0.9834117]\n",
      "[0.98302865]\n",
      "[0.97946787]\n",
      "[0.98286]\n",
      "[0.97276056]\n",
      "[0.983328]\n",
      "[0.978189]\n",
      "[0.95984733]\n",
      "[0.96729815]\n",
      "[0.98400944]\n",
      "[0.9795035]\n",
      "[0.97586226]\n",
      "[0.978454]\n",
      "[0.98230326]\n",
      "[0.9834878]\n",
      "[0.98347837]\n",
      "[0.98096186]\n",
      "[0.979694]\n",
      "[0.9788563]\n",
      "[0.97825855]\n",
      "[0.9694721]\n",
      "[0.9834089]\n",
      "[0.9792268]\n",
      "[0.981451]\n",
      "[0.98289007]\n",
      "[0.98120576]\n",
      "[0.98376316]\n",
      "[0.9791818]\n",
      "[0.9794292]\n",
      "[0.983289]\n",
      "[0.9840528]\n",
      "[0.94763696]\n",
      "[0.94254494]\n",
      "[0.9779117]\n",
      "[0.9840555]\n",
      "[0.9819995]\n",
      "[0.97423977]\n",
      "[0.9839108]\n",
      "[0.9773372]\n",
      "[0.9289263]\n",
      "[0.977414]\n",
      "[0.9768891]\n",
      "[0.98287857]\n",
      "[0.9773372]\n",
      "[0.9834173]\n",
      "[0.98247397]\n",
      "[0.98260236]\n",
      "[0.9822418]\n",
      "[0.98131233]\n",
      "[0.98052835]\n",
      "[0.9834701]\n",
      "[0.951276]\n",
      "[0.9820008]\n",
      "[0.97980505]\n",
      "[0.98327595]\n",
      "[0.94254494]\n",
      "[0.98248714]\n",
      "[0.95131934]\n",
      "[0.9782229]\n",
      "[0.98167443]\n",
      "[0.9835244]\n",
      "[0.9677946]\n",
      "[0.9822183]\n",
      "[0.98005795]\n",
      "[0.9834699]\n",
      "[0.9819092]\n",
      "[0.9822571]\n",
      "[0.98289424]\n",
      "[0.96627855]\n",
      "[0.98179233]\n",
      "[0.96559614]\n",
      "[0.9781769]\n",
      "[0.9658749]\n",
      "[0.98335344]\n",
      "[0.97321934]\n",
      "[0.9505254]\n",
      "[0.98252785]\n",
      "[0.9702922]\n"
     ]
    }
   ],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in rounded_predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 7)                 525       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 9)                 72        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 5)                 50        \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 7)                 42        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 5)                 40        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825\n",
      "Trainable params: 825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('model')\n",
    "# Check its architecture\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['rating_good_or_bad'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s2/kst8s98x3wvg1q8531pn80640000gn/T/ipykernel_2325/1322474218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rating_good_or_bad\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['rating_good_or_bad'] not in index\""
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = Path('input_test.csv')\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.loc[:, columns].copy()\n",
    "\n",
    "df = df.drop([\"rating_good_or_bad\"], axis=1)\n",
    "\n",
    "ans = nn.predict(df)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86969af4118fd2beaee010b14a97d3c8fe7dc31ff55f1528eea7eaecb45368d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
